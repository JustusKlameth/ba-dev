@misc{ai@metaLlama3Herd2024,
  title = {The {{Llama}} 3 {{Herd}} of {{Models}} {\textbar} {{Research}} - {{AI}} at {{Meta}}},
  author = {AI @ Meta, Llama Team},
  year = {2024},
  month = jul,
  urldate = {2024-09-18},
  howpublished = {https://ai.meta.com/research/publications/the-llama-3-herd-of-models/},
  keywords = {Beispiel,Quelle},
  file = {/Users/justusklameth/Zotero/storage/JT3H9BFY/453304228_1160109801904614_7143520450792086005_n.pdf;/Users/justusklameth/Zotero/storage/VFPLMIM6/the-llama-3-herd-of-models.html}
}

@misc{amodeiConcreteProblemsAI2016,
  title = {Concrete {{Problems}} in {{AI Safety}}},
  author = {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  year = {2016},
  month = jul,
  number = {arXiv:1606.06565},
  eprint = {1606.06565},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1606.06565},
  urldate = {2025-01-02},
  abstract = {Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.},
  archiveprefix = {arXiv},
  keywords = {Grundlage},
  file = {/Users/justusklameth/Zotero/storage/N35ZT456/Amodei et al. - 2016 - Concrete Problems in AI Safety.pdf;/Users/justusklameth/Zotero/storage/J5MTBQG8/1606.html}
}

@misc{azerbayevLlemmaOpenLanguage2024,
  title = {Llemma: {{An Open Language Model For Mathematics}}},
  shorttitle = {Llemma},
  author = {Azerbayev, Zhangir and Schoelkopf, Hailey and Paster, Keiran and Santos, Marco Dos and McAleer, Stephen and Jiang, Albert Q. and Deng, Jia and Biderman, Stella and Welleck, Sean},
  year = {2024},
  month = mar,
  number = {arXiv:2310.10631},
  eprint = {2310.10631},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.10631},
  urldate = {2025-01-02},
  abstract = {We present Llemma, a large language model for mathematics. We continue pretraining Code Llama on the Proof-Pile-2, a mixture of scientific papers, web data containing mathematics, and mathematical code, yielding Llemma. On the MATH benchmark Llemma outperforms all known open base models, as well as the unreleased Minerva model suite on an equi-parameter basis. Moreover, Llemma is capable of tool use and formal theorem proving without any further finetuning. We openly release all artifacts, including 7 billion and 34 billion parameter models, the Proof-Pile-2, and code to replicate our experiments.},
  archiveprefix = {arXiv},
  file = {/Users/justusklameth/Zotero/storage/9MCCIGDC/Azerbayev et al. - 2024 - Llemma An Open Language Model For Mathematics.pdf;/Users/justusklameth/Zotero/storage/FX5HRG2F/2310.html}
}

@misc{benchekrounWorldSenseSyntheticBenchmark2023,
  title = {{{WorldSense}}: {{A Synthetic Benchmark}} for {{Grounded Reasoning}} in {{Large Language Models}}},
  shorttitle = {{{WorldSense}}},
  author = {Benchekroun, Youssef and Dervishi, Megi and Ibrahim, Mark and Gaya, Jean-Baptiste and Martinet, Xavier and Mialon, Gr{\'e}goire and Scialom, Thomas and Dupoux, Emmanuel and Hupkes, Dieuwke and Vincent, Pascal},
  year = {2023},
  month = nov,
  number = {arXiv:2311.15930},
  eprint = {2311.15930},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.15930},
  urldate = {2024-05-16},
  abstract = {We propose WorldSense, a benchmark designed to assess the extent to which LLMs are consistently able to sustain tacit world models, by testing how they draw simple inferences from descriptions of simple arrangements of entities. Worldsense is a synthetic benchmark with three problem types, each with their own trivial control, which explicitly avoids bias by decorrelating the abstract structure of problems from the vocabulary and expressions, and by decorrelating all problem subparts with the correct response. We run our benchmark on three state-of-the-art chat-LLMs (GPT3.5, GPT4 and Llama2-chat) and show that these models make errors even with as few as three objects. Furthermore, they have quite heavy response biases, preferring certain responses irrespective of the question. Errors persist even with chain-of-thought prompting and in-context learning. Lastly, we show that while finetuning on similar problems does result in substantial improvements -- within- and out-of-distribution -- the finetuned models do not generalise beyond a constraint problem space.},
  archiveprefix = {arXiv},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/H7EYKXWJ/Benchekroun et al. - 2023 - WorldSense A Synthetic Benchmark for Grounded Rea.pdf;/Users/justusklameth/Zotero/storage/NGAR8SCI/2311.html}
}

@inproceedings{bhandariAreLargeLanguage2023,
  title = {Are {{Large Language Models Geospatially Knowledgeable}}?},
  booktitle = {Proceedings of the 31st {{ACM International Conference}} on {{Advances}} in {{Geographic Information Systems}}},
  author = {Bhandari, Prabin and Anastasopoulos, Antonios and Pfoser, Dieter},
  year = {2023},
  month = dec,
  series = {{{SIGSPATIAL}} '23},
  pages = {1--4},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3589132.3625625},
  urldate = {2024-05-16},
  abstract = {Despite the impressive performance of Large Language Models (LLM) for various natural language processing tasks, little is known about their comprehension of geographic data and related ability to facilitate informed geospatial decision-making. This paper investigates the extent of geospatial knowledge, awareness, and reasoning abilities encoded within such pretrained LLMs. With a focus on autoregressive language models, we devise experimental approaches related to (i) probing LLMs for geo-coordinates to assess geospatial knowledge, (ii) using geospatial and non-geospatial prepositions to gauge their geospatial awareness, and (iii) utilizing a multidimensional scaling (MDS) experiment to assess the models' geospatial reasoning capabilities and to determine locations of cities based on prompting. Our results confirm that it does not only take larger but also more sophisticated LLMs to synthesize geospatial knowledge from textual information. As such, this research contributes to understanding the potential and limitations of LLMs in dealing with geospatial information.},
  isbn = {9798400701689},
  keywords = {Beispiel,Quelle},
  file = {/Users/justusklameth/Zotero/storage/P4EYB85X/Bhandari et al. - 2023 - Are Large Language Models Geospatially Knowledgeab.pdf}
}

@misc{bhandariAreLargeLanguage2023a,
  title = {Are {{Large Language Models Geospatially Knowledgeable}}?},
  author = {Bhandari, Prabin and Anastasopoulos, Antonios and Pfoser, Dieter},
  year = {2023},
  month = oct,
  number = {arXiv:2310.13002},
  eprint = {2310.13002},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.13002},
  urldate = {2025-01-01},
  abstract = {Despite the impressive performance of Large Language Models (LLM) for various natural language processing tasks, little is known about their comprehension of geographic data and related ability to facilitate informed geospatial decision-making. This paper investigates the extent of geospatial knowledge, awareness, and reasoning abilities encoded within such pretrained LLMs. With a focus on autoregressive language models, we devise experimental approaches related to (i) probing LLMs for geo-coordinates to assess geospatial knowledge, (ii) using geospatial and non-geospatial prepositions to gauge their geospatial awareness, and (iii) utilizing a multidimensional scaling (MDS) experiment to assess the models' geospatial reasoning capabilities and to determine locations of cities based on prompting. Our results confirm that it does not only take larger, but also more sophisticated LLMs to synthesize geospatial knowledge from textual information. As such, this research contributes to understanding the potential and limitations of LLMs in dealing with geospatial information.},
  archiveprefix = {arXiv},
  keywords = {Quelle},
  file = {/Users/justusklameth/Zotero/storage/QBLBXIEG/Bhandari et al. - 2023 - Are Large Language Models Geospatially Knowledgeab.pdf;/Users/justusklameth/Zotero/storage/IJ97MMW8/2310.html}
}

@inproceedings{brownLanguageModelsAre2020,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  volume = {33},
  pages = {1877--1901},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-05-17},
  abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
  keywords = {Grundlage},
  file = {/Users/justusklameth/Zotero/storage/VQWV2VPT/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf}
}

@misc{capgeminiGenerativeKIVerwendungszweck2023,
  title = {{Generative KI - Verwendungszweck 2023}},
  author = {Capgemini},
  year = {2023},
  journal = {Statista},
  urldate = {2025-03-15},
  abstract = {Laut Capgemini nutzen die Befragten generative KI f{\"u}r kreative Zwecke wie die eigentliche Erstellung von Content (52 Prozent), aber auch im Schritt davor f{\"u}r die Ideensammlung mittels Brainstorming (28 Prozent).},
  howpublished = {https://de.statista.com/statistik/daten/studie/1403840/umfrage/verwendungszweck-generativer-ki-tools/},
  langid = {ngerman},
  file = {/Users/justusklameth/Zotero/storage/PTCK37CY/verwendungszweck-generativer-ki-tools.html}
}

@article{guanLeveragingPretrainedLarge2023,
  title = {Leveraging {{Pre-trained Large Language Models}} to {{Construct}} and {{Utilize World Models}} for {{Model-based Task Planning}}},
  author = {Guan, Lin and Valmeekam, Karthik and Sreedharan, Sarath and Kambhampati, Subbarao},
  year = {2023},
  month = dec,
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {79081--79094},
  urldate = {2024-08-29},
  langid = {english},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/CEC9LTH2/Guan et al. - 2023 - Leveraging Pre-trained Large Language Models to Co.pdf}
}

@misc{horizontUmfrageZurNutzung2023,
  title = {{Umfrage zur Nutzung von KI-Diensten 2023}},
  author = {Horizont},
  year = {2023},
  journal = {Statista},
  urldate = {2025-03-15},
  abstract = {K{\"u}nstliche Intelligenz wird in Zukunft in vielen Bereichen Anwendung finden und das Leben der Menschen ma{\ss}geblich ver{\"a}ndern.},
  howpublished = {https://de.statista.com/statistik/daten/studie/1373267/umfrage/umfrage-zur-aktiven-nutzung-von-ki-diensten-in-deutschland/},
  langid = {ngerman},
  file = {/Users/justusklameth/Zotero/storage/9KHUEVQB/umfrage-zur-aktiven-nutzung-von-ki-diensten-in-deutschland.html}
}

@misc{huangWordsRoutesApplying2024,
  title = {From {{Words}} to {{Routes}}: {{Applying Large Language Models}} to {{Vehicle Routing}}},
  shorttitle = {From {{Words}} to {{Routes}}},
  author = {Huang, Zhehui and Shi, Guangyao and Sukhatme, Gaurav S.},
  year = {2024},
  month = mar,
  number = {arXiv:2403.10795},
  eprint = {2403.10795},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.10795},
  urldate = {2024-05-16},
  abstract = {LLMs have shown impressive progress in robotics (e.g., manipulation and navigation) with natural language task descriptions. The success of LLMs in these tasks leads us to wonder: What is the ability of LLMs to solve vehicle routing problems (VRPs) with natural language task descriptions? In this work, we study this question in three steps. First, we construct a dataset with 21 types of single- or multi-vehicle routing problems. Second, we evaluate the performance of LLMs across four basic prompt paradigms of text-to-code generation, each involving different types of text input. We find that the basic prompt paradigm, which generates code directly from natural language task descriptions, performs the best for GPT-4, achieving 56\% feasibility, 40\% optimality, and 53\% efficiency. Third, based on the observation that LLMs may not be able to provide correct solutions at the initial attempt, we propose a framework that enables LLMs to refine solutions through self-reflection, including self-debugging and self-verification. With GPT-4, our proposed framework achieves a 16\% increase in feasibility, a 7\% increase in optimality, and a 15\% increase in efficiency. Moreover, we examine the sensitivity of GPT-4 to task descriptions, specifically focusing on how its performance changes when certain details are omitted from the task descriptions, yet the core meaning is preserved. Our findings reveal that such omissions lead to a notable decrease in performance: 4\% in feasibility, 4\% in optimality, and 5\% in efficiency. Website: https://sites.google.com/view/words-to-routes/},
  archiveprefix = {arXiv},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/YCVZSLZ7/Huang et al. - 2024 - From Words to Routes Applying Large Language Mode.pdf;/Users/justusklameth/Zotero/storage/8R3U9HUC/2403.html}
}

@misc{ilyankouCCGPXExtractingHighQuality2024,
  title = {{{CC-GPX}}: {{Extracting High-Quality Annotated Geospatial Data}} from {{Common Crawl}}},
  shorttitle = {{{CC-GPX}}},
  author = {Ilyankou, Ilya and Wang, Meihui and Haworth, James and Cavazzi, Stefano},
  year = {2024},
  month = may,
  number = {arXiv:2405.11039},
  eprint = {2405.11039},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.11039},
  urldate = {2024-06-05},
  abstract = {The Common Crawl (CC) corpus is the largest open web crawl dataset containing 9.5+ petabytes of data captured since 2008. The dataset is instrumental in training large language models, and as such it has been studied for (un)desirable content, and distilled for smaller, domain-specific datasets. However, to our knowledge, no research has been dedicated to using CC as a source of annotated geospatial data. In this paper, we introduce an efficient pipeline to extract annotated user-generated tracks from GPX files found in CC, and the resulting multimodal dataset with 1,416 pairings of human-written descriptions and MultiLineString vector data from the 6 most recent CC releases. The dataset can be used to study people's outdoor activity patterns, the way people talk about their outdoor experiences, and for developing trajectory generation or track annotation models. Our reproducible code is available on GitHub: https://github.com/ilyankou/cc-gpx},
  archiveprefix = {arXiv},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/QK9LJYQC/Ilyankou et al. - 2024 - CC-GPX Extracting High-Quality Annotated Geospati.pdf;/Users/justusklameth/Zotero/storage/VZU48LTG/2405.html}
}

@misc{ilyankouSentenceTransformersLearn2024,
  title = {Do {{Sentence Transformers Learn Quasi-Geospatial Concepts}} from {{General Text}}?},
  author = {Ilyankou, Ilya and Lipani, Aldo and Cavazzi, Stefano and Gao, Xiaowei and Haworth, James},
  year = {2024},
  month = apr,
  number = {arXiv:2404.04169},
  eprint = {2404.04169},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-05-13},
  abstract = {Sentence transformers [1] are language models designed to perform semantic search. This study investigates the capacity of sentence transformers, fine-tuned on general question-answering datasets for asymmetric semantic search, to associate descriptions of human-generated routes across Great Britain with queries often used to describe hiking experiences. We find that sentence transformers have some zero-shot capabilities to understand quasi-geospatial concepts, such as route types and difficulty, suggesting their potential utility for routing recommendation systems.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/5YFVDQRQ/Ilyankou et al. - 2024 - Do Sentence Transformers Learn Quasi-Geospatial Co.pdf}
}

@article{juhaszChatGPTMappingAssistant2023,
  title = {{{ChatGPT}} as a Mapping Assistant: {{A}} Novel Method to Enrich Maps with Generative {{AI}} and Content Derived from Street-Level Photographs},
  shorttitle = {{{ChatGPT}} as a Mapping Assistant},
  author = {Juh{\'a}sz, Levente and Mooney, Peter and Hochmair, Hartwig H. and Guan, Boyuan},
  year = {2023},
  journal = {Spatial Data Science Symposium 2023},
  eprint = {2306.03204},
  primaryclass = {cs},
  doi = {10.25436/E2ZW27},
  urldate = {2024-05-17},
  abstract = {This paper explores the concept of leveraging generative AI as a mapping assistant for enhancing the efficiency of collaborative mapping. We present results of an experiment that combines multiple sources of volunteered geographic information (VGI) and large language models (LLMs). Three analysts described the content of crowdsourced Mapillary street-level photographs taken along roads in a small test area in Miami, Florida. GPT-3.5-turbo was instructed to suggest the most appropriate tagging for each road in OpenStreetMap (OSM). The study also explores the utilization of BLIP-2, a state-of-the-art multimodal pre-training method as an artificial analyst of street-level photographs in addition to human analysts. Results demonstrate two ways to effectively increase the accuracy of mapping suggestions without modifying the underlying AI models: by (1) providing a more detailed description of source photographs, and (2) combining prompt engineering with additional context (e.g. location and objects detected along a road). The first approach increases the suggestion accuracy by up to 29\%, and the second one by up to 20\%.},
  archiveprefix = {arXiv},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/BW55YUG5/Juhász et al. - 2023 - ChatGPT as a mapping assistant A novel method to .pdf;/Users/justusklameth/Zotero/storage/MKR2U7ZG/2306.html}
}

@article{karneyAlgorithmsGeodesics2013,
  title = {Algorithms for Geodesics},
  author = {Karney, Charles F. F.},
  year = {2013},
  month = jan,
  journal = {Journal of Geodesy},
  volume = {87},
  number = {1},
  pages = {43--55},
  issn = {1432-1394},
  doi = {10.1007/s00190-012-0578-z},
  urldate = {2024-09-07},
  abstract = {Algorithms for the computation of geodesics on an ellipsoid of revolution are given. These provide accurate, robust, and fast solutions to the direct and inverse geodesic problems and they allow differential and integral properties of geodesics to be computed.},
  langid = {english},
  keywords = {Quelle},
  file = {/Users/justusklameth/Zotero/storage/53TSVPRJ/Karney - 2013 - Algorithms for geodesics.pdf}
}

@article{katzGPT4PassesBar2024,
  title = {{{GPT-4}} Passes the Bar Exam},
  author = {Katz, Daniel Martin and Bommarito, Michael James and Gao, Shang and Arredondo, Pablo},
  year = {2024},
  month = feb,
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {382},
  number = {2270},
  pages = {20230254},
  publisher = {Royal Society},
  doi = {10.1098/rsta.2023.0254},
  urldate = {2024-06-06},
  abstract = {In this paper, we experimentally evaluate the zero-shot performance of GPT-4 against prior generations of GPT on the entire uniform bar examination (UBE), including not only the multiple-choice multistate bar examination (MBE), but also the open-ended multistate essay exam (MEE) and multistate performance test (MPT) components. On the MBE, GPT-4 significantly outperforms both human test-takers and prior models, demonstrating a 26\% increase over ChatGPT and beating humans in five of seven subject areas. On the MEE and MPT, which have not previously been evaluated by scholars, GPT-4 scores an average of 4.2/6.0 when compared with much lower scores for ChatGPT. Graded across the UBE components, in the manner in which a human test-taker would be, GPT-4 scores approximately 297 points, significantly in excess of the passing threshold for all UBE jurisdictions. These findings document not just the rapid and remarkable advance of large language model performance generally, but also the potential for such models to support the delivery of legal services in society. This article is part of the theme issue `A complexity science approach to law and governance'.},
  keywords = {Beispiel},
  file = {/Users/justusklameth/Zotero/storage/ZWPENE83/Katz et al. - 2024 - GPT-4 passes the bar exam.pdf}
}

@article{liChatDoctorMedicalChat2023,
  title = {{{ChatDoctor}}: {{A Medical Chat Model Fine-Tuned}} on a {{Large Language Model Meta-AI}} ({{LLaMA}}) {{Using Medical Domain Knowledge}}},
  shorttitle = {{{ChatDoctor}}},
  author = {Li, Yunxiang and Li, Zihan and Zhang, Kai and Dan, Ruilong and Jiang, Steve and Zhang, You},
  year = {2023},
  month = jun,
  journal = {Cureus},
  volume = {15},
  number = {6},
  pages = {e40895},
  issn = {2168-8184},
  doi = {10.7759/cureus.40895},
  urldate = {2025-01-02},
  abstract = {Objective, The primary aim of this research was to address the limitations observed in the medical knowledge of prevalent large language models (LLMs) such as ChatGPT, by creating a specialized language model with enhanced accuracy in medical advice., Methods, We achieved this by adapting and refining the large language model meta-AI (LLaMA)~using a large dataset of 100,000 patient-doctor dialogues sourced from a widely used online medical consultation platform. These conversations were cleaned and anonymized to respect privacy concerns. In addition to the model refinement, we incorporated a self-directed information retrieval mechanism, allowing the model to access and utilize real-time information from online sources like Wikipedia and data from curated offline medical databases., Results, The fine-tuning of the model with real-world patient-doctor interactions significantly improved the model's ability to understand patient needs and provide informed advice. By equipping the model with self-directed information retrieval from reliable online and offline sources, we observed substantial improvements in the accuracy of its responses., Conclusion, Our proposed ChatDoctor, represents a significant advancement in medical LLMs, demonstrating a significant improvement in understanding patient inquiries and providing accurate advice. Given the high stakes and low error tolerance in the medical field, such enhancements in providing accurate and reliable information are not only beneficial but essential.},
  pmcid = {PMC10364849},
  pmid = {37492832},
  keywords = {Beispiel},
  file = {/Users/justusklameth/Zotero/storage/YEHJ2PN3/Li et al. - ChatDoctor A Medical Chat Model Fine-Tuned on a L.pdf}
}

@misc{liuPTuningV2Prompt2021,
  title = {P-{{Tuning}} v2: {{Prompt Tuning Can Be Comparable}} to {{Fine-tuning Universally Across Scales}} and {{Tasks}}},
  shorttitle = {P-{{Tuning}} V2},
  author = {Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng Lam and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
  year = {2021},
  month = oct,
  journal = {arXiv.org},
  urldate = {2024-09-05},
  abstract = {Prompt tuning, which only tunes continuous prompts with a frozen language model, substantially reduces per-task storage and memory usage at training. However, in the context of NLU, prior work reveals that prompt tuning does not perform well for normal-sized pretrained models. We also find that existing methods of prompt tuning cannot handle hard sequence labeling tasks, indicating a lack of universality. We present a novel empirical finding that properly optimized prompt tuning can be universally effective across a wide range of model scales and NLU tasks. It matches the performance of finetuning while having only 0.1\%-3\% tuned parameters. Our method P-Tuning v2 is an implementation of Deep Prompt Tuning {\textbackslash}cite\{li2021prefix,qin2021learning\} optimized and adapted for NLU. Given the universality and simplicity of P-Tuning v2, we believe it can serve as an alternative to finetuning and a strong baseline for future research.Our code and data are released at https://github.com/THUDM/P-tuning-v2.},
  howpublished = {https://arxiv.org/abs/2110.07602v3},
  langid = {english},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/92ASFECL/Liu et al. - 2021 - P-Tuning v2 Prompt Tuning Can Be Comparable to Fi.pdf}
}

@misc{maiOpportunitiesChallengesFoundation2023,
  title = {On the {{Opportunities}} and {{Challenges}} of {{Foundation Models}} for {{Geospatial Artificial Intelligence}}},
  author = {Mai, Gengchen and Huang, Weiming and Sun, Jin and Song, Suhang and Mishra, Deepak and Liu, Ninghao and Gao, Song and Liu, Tianming and Cong, Gao and Hu, Yingjie and Cundy, Chris and Li, Ziyuan and Zhu, Rui and Lao, Ni},
  year = {2023},
  month = apr,
  number = {arXiv:2304.06798},
  eprint = {2304.06798},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.06798},
  urldate = {2024-05-17},
  abstract = {Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial subdomains including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, these task-agnostic LLMs can outperform task-specific fully-supervised models in a zero-shot or few-shot learning setting. However, on other geospatial tasks, especially tasks that involve multiple data modalities (e.g., POI-based urban function classification, street view image-based urban noise intensity classification, and remote sensing image scene classification), existing foundation models still underperform task-specific models. Based on these observations, we propose that one of the major challenges of developing a FM for GeoAI is to address the multimodality nature of geospatial tasks. After discussing the distinct challenges of each geospatial data modality, we suggest the possibility of a multimodal foundation model which can reason over various types of geospatial data through geospatial alignments. We conclude this paper by discussing the unique risks and challenges to develop such a model for GeoAI.},
  archiveprefix = {arXiv},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/9FIKGWMV/Mai et al. - 2023 - On the Opportunities and Challenges of Foundation .pdf;/Users/justusklameth/Zotero/storage/JRV9FJZ8/2304.html}
}

@misc{manviGeoLLMExtractingGeospatial2024,
  title = {{{GeoLLM}}: {{Extracting Geospatial Knowledge}} from {{Large Language Models}}},
  shorttitle = {{{GeoLLM}}},
  author = {Manvi, Rohin and Khanna, Samar and Mai, Gengchen and Burke, Marshall and Lobell, David and Ermon, Stefano},
  year = {2024},
  month = feb,
  number = {arXiv:2310.06213},
  eprint = {2310.06213},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.06213},
  urldate = {2024-05-17},
  abstract = {The application of machine learning (ML) in a range of geospatial tasks is increasingly common but often relies on globally available covariates such as satellite imagery that can either be expensive or lack predictive power. Here we explore the question of whether the vast amounts of knowledge found in Internet language corpora, now compressed within large language models (LLMs), can be leveraged for geospatial prediction tasks. We first demonstrate that LLMs embed remarkable spatial information about locations, but naively querying LLMs using geographic coordinates alone is ineffective in predicting key indicators like population density. We then present GeoLLM, a novel method that can effectively extract geospatial knowledge from LLMs with auxiliary map data from OpenStreetMap. We demonstrate the utility of our approach across multiple tasks of central interest to the international community, including the measurement of population density and economic livelihoods. Across these tasks, our method demonstrates a 70\% improvement in performance (measured using Pearson's \$r{\textasciicircum}2\$) relative to baselines that use nearest neighbors or use information directly from the prompt, and performance equal to or exceeding satellite-based benchmarks in the literature. With GeoLLM, we observe that GPT-3.5 outperforms Llama 2 and RoBERTa by 19\% and 51\% respectively, suggesting that the performance of our method scales well with the size of the model and its pretraining dataset. Our experiments reveal that LLMs are remarkably sample-efficient, rich in geospatial information, and robust across the globe. Crucially, GeoLLM shows promise in mitigating the limitations of existing geospatial covariates and complementing them well. Code is available on the project website: https://rohinmanvi.github.io/GeoLLM},
  archiveprefix = {arXiv},
  keywords = {Beispiel},
  file = {/Users/justusklameth/Zotero/storage/WWMQAI2G/Manvi et al. - 2024 - GeoLLM Extracting Geospatial Knowledge from Large.pdf;/Users/justusklameth/Zotero/storage/8SZEC9A9/2310.html}
}

@misc{noriCapabilitiesGPT4Medical2023,
  title = {Capabilities of {{GPT-4}} on {{Medical Challenge Problems}}},
  author = {Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
  year = {2023},
  month = apr,
  number = {arXiv:2303.13375},
  eprint = {2303.13375},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.13375},
  urldate = {2024-06-06},
  abstract = {Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation across various domains, including medicine. We present a comprehensive evaluation of GPT-4, a state-of-the-art LLM, on medical competency examinations and benchmark datasets. GPT-4 is a general-purpose model that is not specialized for medical problems through training or engineered to solve clinical tasks. Our analysis covers two sets of official practice materials for the USMLE, a three-step examination program used to assess clinical competency and grant licensure in the United States. We also evaluate performance on the MultiMedQA suite of benchmark datasets. Beyond measuring model performance, experiments were conducted to investigate the influence of test questions containing both text and images on model performance, probe for memorization of content during training, and study probability calibration, which is of critical importance in high-stakes applications like medicine. Our results show that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B). In addition, GPT-4 is significantly better calibrated than GPT-3.5, demonstrating a much-improved ability to predict the likelihood that its answers are correct. We also explore the behavior of the model qualitatively through a case study that shows the ability of GPT-4 to explain medical reasoning, personalize explanations to students, and interactively craft new counterfactual scenarios around a medical case. Implications of the findings are discussed for potential uses of GPT-4 in medical education, assessment, and clinical practice, with appropriate attention to challenges of accuracy and safety.},
  archiveprefix = {arXiv},
  keywords = {Beispiel},
  file = {/Users/justusklameth/Zotero/storage/4NHCEF5J/Nori et al. - 2023 - Capabilities of GPT-4 on Medical Challenge Problem.pdf;/Users/justusklameth/Zotero/storage/X93D6CUM/2303.html}
}

@misc{openaiGPT4TechnicalReport2023,
  title = {{{GPT-4 Technical Report}}},
  author = {OpenAI and Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and Avila, Red and Babuschkin, Igor and Balaji, Suchir and Balcom, Valerie and Baltescu, Paul and Bao, Haiming and Bavarian, Mohammad and Belgum, Jeff and Bello, Irwan and Berdine, Jake and {Bernadett-Shapiro}, Gabriel and Berner, Christopher and Bogdonoff, Lenny and Boiko, Oleg and Boyd, Madelaine and Brakman, Anna-Luisa and Brockman, Greg and Brooks, Tim and Brundage, Miles and Button, Kevin and Cai, Trevor and Campbell, Rosie and Cann, Andrew and Carey, Brittany and Carlson, Chelsea and Carmichael, Rory and Chan, Brooke and Chang, Che and Chantzis, Fotis and Chen, Derek and Chen, Sully and Chen, Ruby and Chen, Jason and Chen, Mark and Chess, Ben and Cho, Chester and Chu, Casey and Chung, Hyung Won and Cummings, Dave and Currier, Jeremiah and Dai, Yunxing and Decareaux, Cory and Degry, Thomas and Deutsch, Noah and Deville, Damien and Dhar, Arka and Dohan, David and Dowling, Steve and Dunning, Sheila and Ecoffet, Adrien and Eleti, Atty and Eloundou, Tyna and Farhi, David and Fedus, Liam and Felix, Niko and Fishman, Sim{\'o}n Posada and Forte, Juston and Fulford, Isabella and Gao, Leo and Georges, Elie and Gibson, Christian and Goel, Vik and Gogineni, Tarun and Goh, Gabriel and {Gontijo-Lopes}, Rapha and Gordon, Jonathan and Grafstein, Morgan and Gray, Scott and Greene, Ryan and Gross, Joshua and Gu, Shixiang Shane and Guo, Yufei and Hallacy, Chris and Han, Jesse and Harris, Jeff and He, Yuchen and Heaton, Mike and Heidecke, Johannes and Hesse, Chris and Hickey, Alan and Hickey, Wade and Hoeschele, Peter and Houghton, Brandon and Hsu, Kenny and Hu, Shengli and Hu, Xin and Huizinga, Joost and Jain, Shantanu and Jain, Shawn and Jang, Joanne and Jiang, Angela and Jiang, Roger and Jin, Haozhun and Jin, Denny and Jomoto, Shino and Jonn, Billie and Jun, Heewoo and Kaftan, Tomer and Kaiser, {\L}ukasz and Kamali, Ali and Kanitscheider, Ingmar and Keskar, Nitish Shirish and Khan, Tabarak and Kilpatrick, Logan and Kim, Jong Wook and Kim, Christina and Kim, Yongjik and Kirchner, Jan Hendrik and Kiros, Jamie and Knight, Matt and Kokotajlo, Daniel and Kondraciuk, {\L}ukasz and Kondrich, Andrew and Konstantinidis, Aris and Kosic, Kyle and Krueger, Gretchen and Kuo, Vishal and Lampe, Michael and Lan, Ikai and Lee, Teddy and Leike, Jan and Leung, Jade and Levy, Daniel and Li, Chak Ming and Lim, Rachel and Lin, Molly and Lin, Stephanie and Litwin, Mateusz and Lopez, Theresa and Lowe, Ryan and Lue, Patricia and Makanju, Anna and Malfacini, Kim and Manning, Sam and Markov, Todor and Markovski, Yaniv and Martin, Bianca and Mayer, Katie and Mayne, Andrew and McGrew, Bob and McKinney, Scott Mayer and McLeavey, Christine and McMillan, Paul and McNeil, Jake and Medina, David and Mehta, Aalok and Menick, Jacob and Metz, Luke and Mishchenko, Andrey and Mishkin, Pamela and Monaco, Vinnie and Morikawa, Evan and Mossing, Daniel and Mu, Tong and Murati, Mira and Murk, Oleg and M{\'e}ly, David and Nair, Ashvin and Nakano, Reiichiro and Nayak, Rajeev and Neelakantan, Arvind and Ngo, Richard and Noh, Hyeonwoo and Ouyang, Long and O'Keefe, Cullen and Pachocki, Jakub and Paino, Alex and Palermo, Joe and Pantuliano, Ashley and Parascandolo, Giambattista and Parish, Joel and Parparita, Emy and Passos, Alex and Pavlov, Mikhail and Peng, Andrew and Perelman, Adam and Peres, Filipe de Avila Belbute and Petrov, Michael and Pinto, Henrique Ponde de Oliveira and Michael and Pokorny and Pokrass, Michelle and Pong, Vitchyr H. and Powell, Tolly and Power, Alethea and Power, Boris and Proehl, Elizabeth and Puri, Raul and Radford, Alec and Rae, Jack and Ramesh, Aditya and Raymond, Cameron and Real, Francis and Rimbach, Kendra and Ross, Carl and Rotsted, Bob and Roussez, Henri and Ryder, Nick and Saltarelli, Mario and Sanders, Ted and Santurkar, Shibani and Sastry, Girish and Schmidt, Heather and Schnurr, David and Schulman, John and Selsam, Daniel and Sheppard, Kyla and Sherbakov, Toki and Shieh, Jessica and Shoker, Sarah and Shyam, Pranav and Sidor, Szymon and Sigler, Eric and Simens, Maddie and Sitkin, Jordan and Slama, Katarina and Sohl, Ian and Sokolowsky, Benjamin and Song, Yang and Staudacher, Natalie and Such, Felipe Petroski and Summers, Natalie and Sutskever, Ilya and Tang, Jie and Tezak, Nikolas and Thompson, Madeleine B. and Tillet, Phil and Tootoonchian, Amin and Tseng, Elizabeth and Tuggle, Preston and Turley, Nick and Tworek, Jerry and Uribe, Juan Felipe Cer{\'o}n and Vallone, Andrea and Vijayvergiya, Arun and Voss, Chelsea and Wainwright, Carroll and Wang, Justin Jay and Wang, Alvin and Wang, Ben and Ward, Jonathan and Wei, Jason and Weinmann, C. J. and Welihinda, Akila and Welinder, Peter and Weng, Jiayi and Weng, Lilian and Wiethoff, Matt and Willner, Dave and Winter, Clemens and Wolrich, Samuel and Wong, Hannah and Workman, Lauren and Wu, Sherwin and Wu, Jeff and Wu, Michael and Xiao, Kai and Xu, Tao and Yoo, Sarah and Yu, Kevin and Yuan, Qiming and Zaremba, Wojciech and Zellers, Rowan and Zhang, Chong and Zhang, Marvin and Zhao, Shengjia and Zheng, Tianhao and Zhuang, Juntang and Zhuk, William and Zoph, Barret},
  year = {2023},
  number = {arXiv:2303.08774},
  eprint = {2303.08774},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.08774},
  urldate = {2024-06-06},
  abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
  archiveprefix = {arXiv},
  keywords = {Beispiel},
  file = {/Users/justusklameth/Zotero/storage/5F389SZQ/OpenAI et al. - 2024 - GPT-4 Technical Report.pdf;/Users/justusklameth/Zotero/storage/2ITIIPX2/2303.html}
}

@inproceedings{patelMappingLanguageModels2021,
  title = {Mapping {{Language Models}} to {{Grounded Conceptual Spaces}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Patel, Roma and Pavlick, Ellie},
  year = {2021},
  month = oct,
  urldate = {2024-08-29},
  abstract = {A fundamental criticism of text-only language models (LMs) is their lack of grounding---that is, the ability to tie a word for which they have learned a representation, to its actual use in the world. However, despite this limitation, large pre-trained LMs have been shown to have a remarkable grasp of the conceptual structure of language, as demonstrated by their ability to answer questions, generate fluent text, or make inferences about entities, objects, and properties that they have never physically observed. In this work we investigate the extent to which the rich conceptual structure that LMs learn indeed reflects the conceptual structure of the non-linguistic world---which is something that LMs have never observed. We do this by testing whether the LMs can learn to map an entire conceptual domain (e.g., direction or colour) onto a grounded world representation given only a small number of examples. For example, we show a model what the word ``left" means using a textual depiction of a grid world, and assess how well it can generalise to related concepts, for example, the word ``right", in a similar grid world. We investigate a range of generative language models of varying sizes (including GPT-2 and GPT-3), and see that although the smaller models struggle to perform this mapping, the largest model can not only learn to ground the concepts that it is explicitly taught, but appears to generalise to several instances of unseen concepts as well. Our results suggest an alternative means of building grounded language models: rather than learning grounded representations ``from scratch'', it is possible that large text-only models learn a sufficiently rich conceptual structure that could allow them to be grounded in a data-efficient way.},
  langid = {english},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/HUDLU5I7/Patel and Pavlick - 2021 - Mapping Language Models to Grounded Conceptual Spa.pdf}
}

@misc{poldrackAIassistedCodingExperiments2023,
  title = {{{AI-assisted}} Coding: {{Experiments}} with {{GPT-4}}},
  shorttitle = {{{AI-assisted}} Coding},
  author = {Poldrack, Russell A. and Lu, Thomas and Begu{\v s}, Ga{\v s}per},
  year = {2023},
  month = apr,
  number = {arXiv:2304.13187},
  eprint = {2304.13187},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.13187},
  urldate = {2024-06-06},
  abstract = {Artificial intelligence (AI) tools based on large language models have acheived human-level performance on some computer programming tasks. We report several experiments using GPT-4 to generate computer code. These experiments demonstrate that AI code generation using the current generation of tools, while powerful, requires substantial human validation to ensure accurate performance. We also demonstrate that GPT-4 refactoring of existing code can significantly improve that code along several established metrics for code quality, and we show that GPT-4 can generate tests with substantial coverage, but that many of the tests fail when applied to the associated code. These findings suggest that while AI coding tools are very powerful, they still require humans in the loop to ensure validity and accuracy of the results.},
  archiveprefix = {arXiv},
  keywords = {Beispiel},
  file = {/Users/justusklameth/Zotero/storage/HE9VG8B3/Poldrack et al. - 2023 - AI-assisted coding Experiments with GPT-4.pdf;/Users/justusklameth/Zotero/storage/62VVFPGB/2304.html}
}

@misc{razeghiImpactPretrainingTerm2022,
  title = {Impact of {{Pretraining Term Frequencies}} on {{Few-Shot Reasoning}}},
  author = {Razeghi, Yasaman and Logan IV, Robert L. and Gardner, Matt and Singh, Sameer},
  year = {2022},
  month = may,
  number = {arXiv:2202.07206},
  eprint = {2202.07206},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-05-13},
  abstract = {Pretrained Language Models (LMs) have demonstrated ability to perform numerical reasoning by extrapolating from a few examples in few-shot settings. However, the extent to which this extrapolation relies on robust reasoning is unclear. In this paper, we investigate how well these models reason with terms that are less frequent in the pretraining data. In particular, we examine the correlations between the model performance on test instances and the frequency of terms from those instances in the pretraining data. We measure the strength of this correlation for a number of GPT-based language models (pretrained on the Pile dataset) on various numerical deduction tasks (e.g., arithmetic and unit conversion). Our results consistently demonstrate that models are more accurate on instances whose terms are more prevalent, in some cases above 70\% (absolute) more accurate on the top 10\% frequent terms in comparison to the bottom 10\%. Overall, although LMs exhibit strong performance at few-shot numerical reasoning tasks, our results raise the question of how much models actually generalize beyond pretraining data, and we encourage researchers to take the pretraining data into account when interpreting evaluation results.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/HWWCQC4Q/Razeghi et al. - 2022 - Impact of Pretraining Term Frequencies on Few-Shot.pdf}
}

@misc{robertsChartingNewTerritories2024,
  title = {Charting {{New Territories}}: {{Exploring}} the {{Geographic}} and {{Geospatial Capabilities}} of {{Multimodal LLMs}}},
  shorttitle = {Charting {{New Territories}}},
  author = {Roberts, Jonathan and L{\"u}ddecke, Timo and Sheikh, Rehan and Han, Kai and Albanie, Samuel},
  year = {2024},
  month = jan,
  number = {arXiv:2311.14656},
  eprint = {2311.14656},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.14656},
  urldate = {2024-05-16},
  abstract = {Multimodal large language models (MLLMs) have shown remarkable capabilities across a broad range of tasks but their knowledge and abilities in the geographic and geospatial domains are yet to be explored, despite potential wide-ranging benefits to navigation, environmental research, urban development, and disaster response. We conduct a series of experiments exploring various vision capabilities of MLLMs within these domains, particularly focusing on the frontier model GPT-4V, and benchmark its performance against open-source counterparts. Our methodology involves challenging these models with a small-scale geographic benchmark consisting of a suite of visual tasks, testing their abilities across a spectrum of complexity. The analysis uncovers not only where such models excel, including instances where they outperform humans, but also where they falter, providing a balanced view of their capabilities in the geographic domain. To enable the comparison and evaluation of future models, our benchmark will be publicly released.},
  archiveprefix = {arXiv},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/I28XSL7Z/Roberts et al. - 2024 - Charting New Territories Exploring the Geographic.pdf;/Users/justusklameth/Zotero/storage/4GV7YL2Q/2311.html}
}

@misc{robertsGPT4GEOHowLanguage2023,
  title = {{{GPT4GEO}}: {{How}} a {{Language Model Sees}} the {{World}}'s {{Geography}}},
  shorttitle = {{{GPT4GEO}}},
  author = {Roberts, Jonathan and L{\"u}ddecke, Timo and Das, Sowmen and Han, Kai and Albanie, Samuel},
  year = {2023},
  month = may,
  number = {arXiv:2306.00020},
  eprint = {2306.00020},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-05-13},
  abstract = {Large language models (LLMs) have shown remarkable capabilities across a broad range of tasks involving question answering and the generation of coherent text and code. Comprehensively understanding the strengths and weaknesses of LLMs is beneficial for safety, downstream applications and improving performance. In this work, we investigate the degree to which GPT-4 has acquired factual geographic knowledge and is capable of using this knowledge for interpretative reasoning, which is especially important for applications that involve geographic data, such as geospatial analysis, supply chain management, and disaster response. To this end, we design and conduct a series of diverse experiments, starting from factual tasks such as location, distance and elevation estimation to more complex questions such as generating country outlines and travel networks, route finding under constraints and supply chain analysis. We provide a broad characterisation of what GPT-4 (without plugins or Internet access) knows about the world, highlighting both potentially surprising capabilities but also limitations.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Beispiel,Quelle},
  file = {/Users/justusklameth/Zotero/storage/KEG3KP45/Roberts et al. - 2023 - GPT4GEO How a Language Model Sees the World's Geo.pdf}
}

@misc{roziereCodeLlamaOpen2024,
  title = {Code {{Llama}}: {{Open Foundation Models}} for {{Code}}},
  shorttitle = {Code {{Llama}}},
  author = {Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and Rapin, J{\'e}r{\'e}my and Kozhevnikov, Artyom and Evtimov, Ivan and Bitton, Joanna and Bhatt, Manish and Ferrer, Cristian Canton and Grattafiori, Aaron and Xiong, Wenhan and D{\'e}fossez, Alexandre and Copet, Jade and Azhar, Faisal and Touvron, Hugo and Martin, Louis and Usunier, Nicolas and Scialom, Thomas and Synnaeve, Gabriel},
  year = {2024},
  month = jan,
  number = {arXiv:2308.12950},
  eprint = {2308.12950},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.12950},
  urldate = {2025-01-02},
  abstract = {We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B, 34B and 70B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B, 13B and 70B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 67\% and 65\% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every other publicly available model on MultiPL-E. We release Code Llama under a permissive license that allows for both research and commercial use.},
  archiveprefix = {arXiv},
  keywords = {Beispiel},
  file = {/Users/justusklameth/Zotero/storage/PMYPJCQD/Rozière et al. - 2024 - Code Llama Open Foundation Models for Code.pdf;/Users/justusklameth/Zotero/storage/6BUH7VGS/2308.html}
}

@article{salmasExtractingGeographicKnowledge,
  title = {Extracting {{Geographic Knowledge}} from {{Large Language Models}}: {{An Experiment}}},
  author = {Salmas, Konstantinos and Pantazi, Despina-Athanasia and Koubarakis, Manolis},
  abstract = {We perform an experimental analysis of how the inner architecture of large language models behaves whilst extracting geographic knowledge. Our aim is to conclude on whether models actually incorporate geospatial information or simply follow statistical patterns in the data; hence to contribute to the research area of creating knowledge graphs from large language models. To achieve this, we study one specific geospatial relation and explore different techniques that leverage the masked language modeling abilities of BERT and RoBERTa. Our study should be construed as a stepping stone to the general study of the ways large language models encapsulate geospatial knowledge. In addition, it has allowed us to observe important points one should focus on when querying language models, which we discuss in detail.},
  langid = {english},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/54G8VVHT/Salmas et al. - Extracting Geographic Knowledge from Large Languag.pdf}
}

@article{taoMappingChatGPT2023,
  title = {Mapping with {{ChatGPT}}},
  author = {Tao, Ran and Xu, Jinwen},
  year = {2023},
  month = jul,
  journal = {ISPRS International Journal of Geo-Information},
  volume = {12},
  number = {7},
  pages = {284},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2220-9964},
  doi = {10.3390/ijgi12070284},
  urldate = {2024-05-16},
  abstract = {The emergence and rapid advancement of large language models (LLMs), represented by OpenAI's Generative Pre-trained Transformer (GPT), has brought up new opportunities across various industries and disciplines. These cutting-edge technologies are transforming the way we interact with information, communicate, and solve complex problems. We conducted a pilot study exploring making maps with ChatGPT, a popular artificial intelligence (AI) chatbot. Specifically, we tested designing thematic maps using given or public geospatial data, as well as creating mental maps purely using textual descriptions of geographic space. We conclude that ChatGPT provides a useful alternative solution for mapping given its unique advantages, such as lowering the barrier to producing maps, boosting the efficiency of massive map production, and understanding geographical space with its spatial thinking capability. However, mapping with ChatGPT still has limitations at the current stage, such as its unequal benefits for different users and dependence on user intervention for quality control.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/LA5FTLUA/Tao and Xu - 2023 - Mapping with ChatGPT.pdf}
}

@misc{touvronLlama2Open2023,
  title = {Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}},
  shorttitle = {Llama 2},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  year = {2023},
  month = jul,
  number = {arXiv:2307.09288},
  eprint = {2307.09288},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.09288},
  urldate = {2025-03-07},
  abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/justusklameth/Zotero/storage/53FRJQB5/Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Model.pdf;/Users/justusklameth/Zotero/storage/7WQZEG45/2307.html}
}

@misc{touvronLLaMAOpenEfficient2023,
  title = {{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}},
  shorttitle = {{{LLaMA}}},
  author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  year = {2023},
  month = feb,
  number = {arXiv:2302.13971},
  eprint = {2302.13971},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.13971},
  urldate = {2025-01-01},
  abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.},
  archiveprefix = {arXiv},
  keywords = {Quelle},
  file = {/Users/justusklameth/Zotero/storage/XBL5W2FC/Touvron et al. - 2023 - LLaMA Open and Efficient Foundation Language Mode.pdf;/Users/justusklameth/Zotero/storage/VMEMI86Q/2302.html}
}

@misc{vafaEvaluatingWorldModel2024,
  title = {Evaluating the {{World Model Implicit}} in a {{Generative Model}}},
  author = {Vafa, Keyon and Chen, Justin Y. and Kleinberg, Jon and Mullainathan, Sendhil and Rambachan, Ashesh},
  year = {2024},
  month = jun,
  number = {arXiv:2406.03689},
  eprint = {2406.03689},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2406.03689},
  urldate = {2024-06-21},
  abstract = {Recent work suggests that large language models may implicitly learn world models. How should we assess this possibility? We formalize this question for the case where the underlying reality is governed by a deterministic finite automaton. This includes problems as diverse as simple logical reasoning, geographic navigation, game-playing, and chemistry. We propose new evaluation metrics for world model recovery inspired by the classic Myhill-Nerode theorem from language theory. We illustrate their utility in three domains: game playing, logic puzzles, and navigation. In all domains, the generative models we consider do well on existing diagnostics for assessing world models, but our evaluation metrics reveal their world models to be far less coherent than they appear. Such incoherence creates fragility: using a generative model to solve related but subtly different tasks can lead it to fail badly. Building generative models that meaningfully capture the underlying logic of the domains they model would be immensely valuable; our results suggest new ways to assess how close a given model is to that goal.},
  archiveprefix = {arXiv},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/Z6BU6XMV/Vafa et al. - 2024 - Evaluating the World Model Implicit in a Generative Model.pdf}
}

@inproceedings{vaswaniAttentionAllYou2017,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-05-17},
  abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
  keywords = {Grundlage},
  file = {/Users/justusklameth/Zotero/storage/NDRXKD8S/Vaswani et al. - 2017 - Attention is All you Need.pdf}
}

@article{wasilewskiMeasuringPerceivedIQ,
  title = {Measuring the {{Perceived IQ}} of {{Multimodal Large Language Models Using Standardized IQ Tests}}},
  author = {Wasilewski, Eryk and Jablonski, Mirek},
  urldate = {2024-08-28},
  abstract = {Evaluating the intelligence of multimodal large language models (LLMs) using adapted human IQ tests poses unique challenges and opportunities for understanding AI capabilities. By applying the Wechsler Adult Intelligence Scale (WAIS), customized to as},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/SK77T3EV/Wasilewski and Jablonski - Measuring the Perceived IQ of Multimodal Large Lan.pdf}
}

@misc{yamadaEvaluatingSpatialUnderstanding2024,
  title = {Evaluating {{Spatial Understanding}} of {{Large Language Models}}},
  author = {Yamada, Yutaro and Bao, Yihan and Lampinen, Andrew K. and Kasai, Jungo and Yildirim, Ilker},
  year = {2024},
  month = apr,
  number = {arXiv:2310.14540},
  eprint = {2310.14540},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.14540},
  urldate = {2024-06-07},
  abstract = {Large language models (LLMs) show remarkable capabilities across a variety of tasks. Despite the models only seeing text in training, several recent studies suggest that LLM representations implicitly capture aspects of the underlying grounded concepts. Here, we explore LLM representations of a particularly salient kind of grounded knowledge -- spatial relationships. We design natural-language navigation tasks and evaluate the ability of LLMs, in particular GPT-3.5-turbo, GPT-4, and Llama2 series models, to represent and reason about spatial structures. These tasks reveal substantial variability in LLM performance across different spatial structures, including square, hexagonal, and triangular grids, rings, and trees. In extensive error analysis, we find that LLMs' mistakes reflect both spatial and non-spatial factors. These findings suggest that LLMs appear to capture certain aspects of spatial structure implicitly, but room for improvement remains.},
  archiveprefix = {arXiv},
  keywords = {Beispiel},
  file = {/Users/justusklameth/Zotero/storage/NZNHJ3PF/Yamada et al. - 2024 - Evaluating Spatial Understanding of Large Language.pdf;/Users/justusklameth/Zotero/storage/BJ6E76KM/2310.html}
}

@misc{zhangGeoGPTUnderstandingProcessing2023,
  title = {{{GeoGPT}}: {{Understanding}} and {{Processing Geospatial Tasks}} through {{An Autonomous GPT}}},
  shorttitle = {{{GeoGPT}}},
  author = {Zhang, Yifan and Wei, Cheng and Wu, Shangyou and He, Zhengting and Yu, Wenhao},
  year = {2023},
  month = jul,
  number = {arXiv:2307.07930},
  eprint = {2307.07930},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.07930},
  urldate = {2024-05-16},
  abstract = {Decision-makers in GIS need to combine a series of spatial algorithms and operations to solve geospatial tasks. For example, in the task of facility siting, the Buffer tool is usually first used to locate areas close or away from some specific entities; then, the Intersect or Erase tool is used to select candidate areas satisfied multiple requirements. Though professionals can easily understand and solve these geospatial tasks by sequentially utilizing relevant tools, it is difficult for non-professionals to handle these problems. Recently, Generative Pre-trained Transformer (e.g., ChatGPT) presents strong performance in semantic understanding and reasoning. Especially, AutoGPT can further extend the capabilities of large language models (LLMs) by automatically reasoning and calling externally defined tools. Inspired by these studies, we attempt to lower the threshold of non-professional users to solve geospatial tasks by integrating the semantic understanding ability inherent in LLMs with mature tools within the GIS community. Specifically, we develop a new framework called GeoGPT that can conduct geospatial data collection, processing, and analysis in an autonomous manner with the instruction of only natural language. In other words, GeoGPT is used to understand the demands of non-professional users merely based on input natural language descriptions, and then think, plan, and execute defined GIS tools to output final effective results. Several cases including geospatial data crawling, spatial query, facility siting, and mapping validate the effectiveness of our framework. Though limited cases are presented in this paper, GeoGPT can be further extended to various tasks by equipping with more GIS tools, and we think the paradigm of "foundational plus professional" implied in GeoGPT provides an effective way to develop next-generation GIS in this era of large foundation models.},
  archiveprefix = {arXiv},
  keywords = {not relevant},
  file = {/Users/justusklameth/Zotero/storage/QZ7MNJYW/Zhang et al. - 2023 - GeoGPT Understanding and Processing Geospatial Ta.pdf;/Users/justusklameth/Zotero/storage/Q857L8R5/2307.html}
}

@misc{zhaoSurveyLargeLanguage2024,
  title = {A {{Survey}} of {{Large Language Models}}},
  author = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and Du, Yifan and Yang, Chen and Chen, Yushuo and Chen, Zhipeng and Jiang, Jinhao and Ren, Ruiyang and Li, Yifan and Tang, Xinyu and Liu, Zikang and Liu, Peiyu and Nie, Jian-Yun and Wen, Ji-Rong},
  year = {2024},
  month = oct,
  number = {arXiv:2303.18223},
  eprint = {2303.18223},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.18223},
  urldate = {2025-01-02},
  abstract = {Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.},
  archiveprefix = {arXiv},
  keywords = {Grundlage},
  file = {/Users/justusklameth/Zotero/storage/MR7ZZ2S8/Zhao et al. - 2024 - A Survey of Large Language Models.pdf;/Users/justusklameth/Zotero/storage/RVA68ER5/2303.html}
}
